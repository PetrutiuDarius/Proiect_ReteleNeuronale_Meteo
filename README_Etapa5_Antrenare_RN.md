# ğŸ“˜ README â€“ Etapa 5: Configurarea È™i antrenarea modelului RN (Time Series)

**Disciplina:** ReÈ›ele Neuronale  
**InstituÈ›ie:** POLITEHNICA BucureÈ™ti â€“ FIIR  
**Student:** PetruÈ›iu Darius-Simion  
**Link Repository GitHub:** https://github.com/PetrutiuDarius/Proiect_ReteleNeuronale_Meteo.git  
**Data:** 11.12.2025  

---

## Scopul etapei 5

AceastÄƒ etapÄƒ vizeazÄƒ antrenarea efectivÄƒ a modelului neuronal pentru prognoza meteorologicÄƒ. Deoarece problema este una de **Regresie pe Serii Temporale** (prezicerea valorilor numerice viitoare bazate pe istoric), abordarea diferÄƒ de clasificarea standard prin arhitecturÄƒ (LSTM/GRU), metrici (MAE/RMSE) È™i strategia de validare (CronologicÄƒ).

**Obiectiv principal:** Antrenarea modelului pe setul de date Hibrid (Real + Sintetic) creat Ã®n Etapa 4, pentru a obÈ›ine o eroare de predicÈ›ie minimÄƒ pe datele din 2024.

---

## 1. PregÄƒtirea datelor pentru antrenare

Ãn Etapa 4, am creat deja un pipeline robust care combinÄƒ datele istorice cu cele simulate ("Black Swan events").

**Verificare status date:**
- **SursÄƒ:** `src/processing/split_data.py` (Scriptul ruleazÄƒ automat Ã®nainte de antrenare).
- **Strategie Split:** CronologicÄƒ (nu stratificatÄƒ, pentru a pÄƒstra cauzalitatea temporalÄƒ).
    - **Train:** 2020-2023 (Real) + Toate Datele Simulate (Extreme).
    - **Validation:** 2024 (Luni Impare).
    - **Test:** 2024 (Luni Pare).
- **Normalizare:** MinMaxScaler fitat doar pe Train, aplicat pe Val/Test.

**Tehnica â€Sliding Windowâ€ (FereastrÄƒ glisantÄƒ):**
ReÈ›eaua nu primeÈ™te datele rÃ¢nd cu rÃ¢nd. Am implementat un generator (`src/neural_network/data_generator.py`) care transformÄƒ datele Ã®n secvenÈ›e 3D:
* **Input (X):** FereastrÄƒ de **24 de ore** din trecut (istoricul recent).
* **Output (y):** Temperatura peste **6 ore** Ã®n viitor (prognoza).

---

## 2. Configurarea modelului È™i hiperparametri (Nivel 1 & 2)

Am ales o arhitecturÄƒ recurentÄƒ (**LSTM** - Long Short-Term Memory) deoarece este standardul de aur pentru date secvenÈ›iale, fiind capabilÄƒ sÄƒ reÈ›inÄƒ dependenÈ›e pe termen lung (ex: tendinÈ›a de Ã®ncÄƒlzire a zilei).

### Tabel hiperparametri È™i justificÄƒri

| **Hiperparametru**   | **Valoare aleasÄƒ**           | **Justificare tehnicÄƒ È™i contextualÄƒ**                                                                                                                                                                               |
|----------------------|------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **ArhitecturÄƒ**      | LSTM (2 straturi)            | Am folosit o arhitecturÄƒ "Stacked LSTM". Primul strat (64 neuroni) extrage trÄƒsÄƒturi complexe (ex: ciclul zi-noapte), iar al doilea (32 neuroni) rafineazÄƒ informaÈ›ia.                                               |
| **Input window (T)** | 24 ore                       | Fereastra de 24h este crucialÄƒ pentru a capta un ciclu diurn complet. Modelul vede evoluÈ›ia temperaturii de ieri pÃ¢nÄƒ azi pentru a prezice viitorul.                                                                 |
| **Loss function**    | **MSE** (Mean Squared Error) | Am ales MSE Ã®n loc de MAE pentru antrenare deoarece MSE penalizeazÄƒ pÄƒtratic erorile mari. Vrem ca modelul sÄƒ fie drastic sancÈ›ionat dacÄƒ rateazÄƒ un vÃ¢rf de caniculÄƒ (eroare mare), forÈ›Ã¢ndu-l sÄƒ Ã®nveÈ›e extremele. |
| **Optimizer**        | Adam (lr=0.001)              | Algoritmul Adam adapteazÄƒ rata de Ã®nvÄƒÈ›are pentru fiecare parametru individual, asigurÃ¢nd o convergenÈ›Äƒ rapidÄƒ fÄƒrÄƒ a necesita reglaje fine manuale.                                                                 |
| **Batch size**       | 64                           | Un compromis Ã®ntre viteza de antrenare È™i stabilitatea gradientului. 64 de exemple sunt procesate simultan Ã®nainte de actualizarea greutÄƒÈ›ilor.                                                                      |
| **Epochs**           | 50 (cu Early Stopping)       | DeÈ™i am setat 50, folosim `EarlyStopping`. DacÄƒ eroarea pe setul de validare nu scade timp de 10 epoci, antrenarea se opreÈ™te automat pentru a preveni memorarea datelor (Overfitting).                              |
| **Dropout**          | 0.2                          | DezactivÄƒm aleatoriu 20% din neuroni la fiecare pas de antrenare. Acest lucru obligÄƒ reÈ›eaua sÄƒ nu se bazeze pe un singur "drum" neuronal, fÄƒcÃ¢nd-o robustÄƒ la zgomot È™i date noi.                                   |

---

## 3. Rezultate È™i metrici de performanÈ›Äƒ

Deoarece proiectul nu este de clasificare, metricile "Accuracy" È™i "Confusion Matrix" nu sunt aplicabile matematic. Am folosit metrici specifice regresiei calculate pe setul de test (anul 2024):

### Èšinte de performanÈ›Äƒ (set de test 2024):
1.  **MAE (Mean Absolute Error):** < 2.5Â°C
    * *SemnificaÈ›ie:* Ãn medie, prognoza greÈ™eÈ™te cu maxim 2.5 grade.
2.  **RMSE (Root Mean Squared Error):** < 3.5Â°C
    * *SemnificaÈ›ie:* PenalizeazÄƒ mai tare erorile mari (extremele).

### Rezultate obÈ›inute (set de test 2024):

| Metrica                           | Valoare obÈ›inutÄƒ | Interpretare |
|:----------------------------------|:-----------------| :--- |
| **MAE (eroare medie absolutÄƒ)**   | **1.4634 Â°C**    | Ãn medie, prognoza sistemului greÈ™eÈ™te cu mai puÈ›in de 1.5 grade. Este un rezultat excelent pentru prognoze pe 6 ore. |
| **RMSE (eroare pÄƒtraticÄƒ medie)** | **2.0461 Â°C**    | Faptul cÄƒ RMSE este apropiat de MAE indicÄƒ faptul cÄƒ nu avem erori catastrofale (predictii aberante) frecvente. |
| **R2 Score**                      | **0.9543**       | Modelul explicÄƒ **95.4%** din variaÈ›ia temperaturii. O valoare foarte apropiatÄƒ de 1 (ideal). |

*(Rezultatele brute se regÄƒsesc Ã®n `results/test_metrics.json`)*.

### Graficul convergenÈ›ei (Loss Curve)
Graficul de mai jos aratÄƒ evoluÈ›ia erorii Ã®n timpul antrenÄƒrii. Se observÄƒ cÄƒ linia portocalie (validare) scade constant È™i rÄƒmÃ¢ne sub cea albastrÄƒ , ceea ce demonstreazÄƒ o capacitate de generalizare foarte bunÄƒ (fÄƒrÄƒ Overfitting).

![Loss Curve](docs/loss_curve.png)

---

## 4. AnalizÄƒ erori Ã®n context industrial (Nivel 2)

### 1. Vizualizare: Real vs. PredicÈ›ie
Graficul de mai jos comparÄƒ valorile reale (Albastru) cu cele prezise de AI (RoÈ™u) pe primele 200 de ore din setul de test.

![Prediction Plot](docs/prediction_plot.png)

### 2. Analiza comportamentului modelului
* **UrmÄƒrirea trendului:** Linia roÈ™ie (AI) urmÄƒreÈ™te aproape perfect linia albastrÄƒ, respectÃ¢nd pantele de Ã®ncÄƒlzire È™i rÄƒcire ale zilei.
* **Comportament la vÃ¢rfuri:** Modelul tinde sÄƒ fie uÈ™or conservator la vÃ¢rfurile extreme (ex: dacÄƒ temperatura realÄƒ e 30Â°C, el prezice 29Â°C). Acest lucru este normal pentru LSTM, care tinde spre medie pentru a minimiza eroarea globalÄƒ.
* **Lag (ÃntÃ¢rziere):** Se observÄƒ o Ã®ntÃ¢rziere minimÄƒ (aproape insesizabilÄƒ vizual), ceea ce valideazÄƒ alegerea ferestrei de 24h.

### 3. Impactul datelor sintetice
DatoritÄƒ introducerii datelor sintetice Ã®n antrenament (Etapa 4), modelul a Ã®nvÄƒÈ›at sÄƒ nu se blocheze la limitele istorice. DeÈ™i testul curent (2024) nu a avut extreme majore, modelul este pregÄƒtit matematic sÄƒ gestioneze valori Ã®n afara distribuÈ›iei normale (ex: >42Â°C).

---

## 5. Structura repository-ului la finalul etapei 5

```text
C:\Users\dariu\Desktop\Retele Neuronale - RN\Proiect\Proiect_ReteleNeuronale_Meteo
â”œâ”€â”€ config/
â”‚   â””â”€â”€ preprocessing_params.pkl       # Scalerul salvat (Standard Prof.)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ generated/                     # Date Hibride & Sintetice
â”‚   â”œâ”€â”€ raw/                           # Date Brute
â”‚   â”œâ”€â”€ test/                          # Set Test (csv)
â”‚   â”œâ”€â”€ train/                         # Set Train (csv)
â”‚   â””â”€â”€ validation/                    # Set Validare (csv)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ loss_curve.png                 # Grafic convergenÈ›Äƒ antrenare â”‚   â”œâ”€â”€ prediction_plot.png            # Grafic comparativ Real vs AI â”‚   â”œâ”€â”€ state-machine-RN.png           # Arhitectura sistemului â”‚   â””â”€â”€ distribution_comparison.png    # Analiza datelor â”œâ”€â”€ models/
â”‚   â””â”€â”€ trained_model.keras            # Modelul LSTM Antrenat (FINAL)
â”œâ”€â”€ results/
â”‚   â””â”€â”€ test_metrics.json              # Rezultatele numerice (MAE, R2)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                      # ConfiguraÈ›ia globalÄƒ
â”‚   â”œâ”€â”€ data_acquisition/              # Module generare date
â”‚   â”œâ”€â”€ neural_network/
â”‚   â”‚   â”œâ”€â”€ data_generator.py          # Sliding Window Logic
â”‚   â”‚   â”œâ”€â”€ evaluate.py                # Script Evaluare & Plotting
â”‚   â”‚   â”œâ”€â”€ model_architecture.py      # DefiniÈ›ia LSTM
â”‚   â”‚   â””â”€â”€ train_model.py             # Script Antrenare
â”‚   â””â”€â”€ processing/                    # Scripturi split & normalizare
â”œâ”€â”€ main.py                            # Orchestrator
â”œâ”€â”€ README.md                          # General
â”œâ”€â”€ README_Etapa4_Arhitectura_SIA.md   # Etapa anterioarÄƒ
â””â”€â”€ README_Etapa5_Antrenare_RN.md      # Acest fiÈ™ier